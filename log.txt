dataset/logs/log.txt
CNTKCommandTrainInfo: train : 80
CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 80
CNTKCommandTrainBegin: train
Learning rate per 60 samples: 0.1
 Minibatch[   1-  10]: loss = 4.805268 * 72, metric = 100.00% * 72;
 Minibatch[  11-  20]: loss = 4.689896 * 66, metric = 100.00% * 66;
 Minibatch[  21-  30]: loss = 4.531246 * 59, metric = 98.31% * 59;
 Minibatch[  31-  40]: loss = 4.704537 * 73, metric = 98.63% * 73;
 Minibatch[  41-  50]: loss = 4.388521 * 75, metric = 94.67% * 75;
Finished Epoch[1 of 80]: [Training] loss = 4.614787 * 402, metric = 98.26% * 402 13.063s ( 30.8 samples/s);
Finished Evaluation [1]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 4.419779 * 64, metric = 95.31% * 64;
 Minibatch[  11-  20]: loss = 4.205790 * 63, metric = 96.83% * 63;
 Minibatch[  21-  30]: loss = 4.396703 * 69, metric = 98.55% * 69;
 Minibatch[  31-  40]: loss = 4.208834 * 70, metric = 91.43% * 70;
 Minibatch[  41-  50]: loss = 4.277669 * 75, metric = 98.67% * 75;
Finished Epoch[2 of 80]: [Training] loss = -705330466893684277854932566016.000000 * 397, metric = -896626911278369343576582222138834944.00% * 397 15.902s ( 25.0 samples/s);
Finished Evaluation [2]: Minibatch[1-14]: metric = 98.81% * 84;
 Minibatch[   1-  10]: loss = 4.469593 * 66, metric = 95.45% * 66;
 Minibatch[  11-  20]: loss = 4.717920 * 69, metric = 100.00% * 69;
 Minibatch[  21-  30]: loss = 4.402590 * 73, metric = 98.63% * 73;
 Minibatch[  31-  40]: loss = 4.570565 * 60, metric = 98.33% * 60;
 Minibatch[  41-  50]: loss = 4.598224 * 75, metric = 98.67% * 75;
Finished Epoch[3 of 80]: [Training] loss = 4.568002 * 398, metric = 98.49% * 398 18.751s ( 21.2 samples/s);
Finished Evaluation [3]: Minibatch[1-14]: metric = 98.81% * 84;
 Minibatch[   1-  10]: loss = 4.425964 * 77, metric = 98.70% * 77;
 Minibatch[  11-  20]: loss = 4.623498 * 73, metric = 100.00% * 73;
 Minibatch[  21-  30]: loss = 4.518566 * 58, metric = 100.00% * 58;
 Minibatch[  31-  40]: loss = 4.484540 * 67, metric = 98.51% * 67;
 Minibatch[  41-  50]: loss = 4.538422 * 77, metric = 98.70% * 77;
Finished Epoch[4 of 80]: [Training] loss = 4.505224 * 407, metric = 98.53% * 407 16.042s ( 25.4 samples/s);
Finished Evaluation [4]: Minibatch[1-14]: metric = 98.81% * 84;
 Minibatch[   1-  10]: loss = 4.562557 * 65, metric = 96.92% * 65;
 Minibatch[  11-  20]: loss = 4.355158 * 73, metric = 93.15% * 73;
 Minibatch[  21-  30]: loss = 4.469952 * 67, metric = 98.51% * 67;
 Minibatch[  31-  40]: loss = 4.418297 * 71, metric = 98.59% * 71;
 Minibatch[  41-  50]: loss = 4.388438 * 62, metric = 98.39% * 62;
Finished Epoch[5 of 80]: [Training] loss = 1066238956764335182148326653952.000000 * 393, metric = 96.69% * 393 30.756s ( 12.8 samples/s);
Finished Evaluation [5]: Minibatch[1-14]: metric = 98.81% * 84;
 Minibatch[   1-  10]: loss = 4.241769 * 61, metric = 90.16% * 61;
 Minibatch[  11-  20]: loss = 4.317891 * 79, metric = 96.20% * 79;
 Minibatch[  21-  30]: loss = 4.349580 * 65, metric = 98.46% * 65;
 Minibatch[  31-  40]: loss = 4.364008 * 67, metric = 100.00% * 67;
 Minibatch[  41-  50]: loss = 4.290099 * 69, metric = 95.65% * 69;
Finished Epoch[6 of 80]: [Training] loss = 691052560136441927864583979008.000000 * 400, metric = -276033196009369237275612937359196160.00% * 400 29.574s ( 13.5 samples/s);
Finished Evaluation [6]: Minibatch[1-14]: metric = 98.81% * 84;
 Minibatch[   1-  10]: loss = 4.182718 * 69, metric = 97.10% * 69;
 Minibatch[  11-  20]: loss = 4.272585 * 68, metric = 97.06% * 68;
 Minibatch[  21-  30]: loss = 4.412751 * 59, metric = 98.31% * 59;
 Minibatch[  31-  40]: loss = 4.297258 * 82, metric = 93.90% * 82;
 Minibatch[  41-  50]: loss = 4.309136 * 68, metric = 95.59% * 68;
Finished Epoch[7 of 80]: [Training] loss = 307601412876443459856105472.000000 * 399, metric = 10411672970771159040.00% * 399 25.863s ( 15.4 samples/s);
Finished Evaluation [7]: Minibatch[1-14]: metric = 98.81% * 84;
 Minibatch[   1-  10]: loss = 4.272111 * 73, metric = 95.89% * 73;
 Minibatch[  11-  20]: loss = 4.394489 * 58, metric = 100.00% * 58;
 Minibatch[  21-  30]: loss = 4.159105 * 62, metric = 96.77% * 62;
 Minibatch[  31-  40]: loss = 4.274947 * 73, metric = 95.89% * 73;
 Minibatch[  41-  50]: loss = 4.256534 * 72, metric = 93.06% * 72;
Finished Epoch[8 of 80]: [Training] loss = 4.265010 * 401, metric = 96.26% * 401 26.085s ( 15.4 samples/s);
Finished Evaluation [8]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 4.140644 * 73, metric = 97.26% * 73;
 Minibatch[  11-  20]: loss = 4.174686 * 72, metric = 94.44% * 72;
 Minibatch[  21-  30]: loss = 4.123774 * 69, metric = 91.30% * 69;
 Minibatch[  31-  40]: loss = 4.209313 * 65, metric = 92.31% * 65;
 Minibatch[  41-  50]: loss = 4.174349 * 56, metric = 91.07% * 56;
Finished Epoch[9 of 80]: [Training] loss = 4.152737 * 398, metric = 93.97% * 398 19.888s ( 20.0 samples/s);
Finished Evaluation [9]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.932384 * 69, metric = 89.86% * 69;
 Minibatch[  11-  20]: loss = 4.116926 * 67, metric = 92.54% * 67;
 Minibatch[  21-  30]: loss = 4.076328 * 76, metric = 92.11% * 76;
 Minibatch[  31-  40]: loss = 4.127079 * 60, metric = 95.00% * 60;
 Minibatch[  41-  50]: loss = 4.089289 * 68, metric = 94.12% * 68;
Finished Epoch[10 of 80]: [Training] loss = 16473388153462818900803584.000000 * 397, metric = 3268312682408961823550268768256.00% * 397 20.380s ( 19.5 samples/s);
Finished Evaluation [10]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.985049 * 72, metric = 87.50% * 72;
 Minibatch[  11-  20]: loss = 4.117779 * 81, metric = 95.06% * 81;
 Minibatch[  21-  30]: loss = 4.123594 * 70, metric = 94.29% * 70;
 Minibatch[  31-  40]: loss = 3.931181 * 64, metric = 92.19% * 64;
 Minibatch[  41-  50]: loss = 4.022387 * 61, metric = 96.72% * 61;
Finished Epoch[11 of 80]: [Training] loss = 4.035257 * 397, metric = 92.19% * 397 20.016s ( 19.8 samples/s);
Finished Evaluation [11]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.914628 * 58, metric = 91.38% * 58;
 Minibatch[  11-  20]: loss = 4.042074 * 67, metric = 92.54% * 67;
 Minibatch[  21-  30]: loss = 3.915509 * 61, metric = 90.16% * 61;
 Minibatch[  31-  40]: loss = 3.958889 * 66, metric = 86.36% * 66;
 Minibatch[  41-  50]: loss = 4.045319 * 80, metric = 92.50% * 80;
Finished Epoch[12 of 80]: [Training] loss = 9094663560574844646285377536.000000 * 400, metric = 50426752473391639803477603909632.00% * 400 23.861s ( 16.8 samples/s);
Finished Evaluation [12]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.895691 * 64, metric = 92.19% * 64;
 Minibatch[  11-  20]: loss = 4.009370 * 66, metric = 100.00% * 66;
 Minibatch[  21-  30]: loss = 3.945630 * 67, metric = 89.55% * 67;
 Minibatch[  31-  40]: loss = 4.082959 * 72, metric = 94.44% * 72;
 Minibatch[  41-  50]: loss = 3.855886 * 69, metric = 92.75% * 69;
Finished Epoch[13 of 80]: [Training] loss = 3.922487 * 398, metric = 93.72% * 398 25.469s ( 15.6 samples/s);
Finished Evaluation [13]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 4.011965 * 67, metric = 94.03% * 67;
 Minibatch[  11-  20]: loss = 3.825432 * 73, metric = 94.52% * 73;
 Minibatch[  21-  30]: loss = 3.811372 * 68, metric = 95.59% * 68;
 Minibatch[  31-  40]: loss = 3.963804 * 74, metric = 95.95% * 74;
 Minibatch[  41-  50]: loss = 4.065494 * 66, metric = 93.94% * 66;
Finished Epoch[14 of 80]: [Training] loss = 24324841249797128631353344.000000 * 405, metric = 3051827264045288323653906202624.00% * 405 21.502s ( 18.8 samples/s);
Finished Evaluation [14]: Minibatch[1-14]: metric = 98.81% * 84;
 Minibatch[   1-  10]: loss = 3.859265 * 67, metric = 92.54% * 67;
 Minibatch[  11-  20]: loss = 4.005825 * 72, metric = 93.06% * 72;
 Minibatch[  21-  30]: loss = 3.791788 * 77, metric = 88.31% * 77;
 Minibatch[  31-  40]: loss = 3.788080 * 67, metric = 94.03% * 67;
 Minibatch[  41-  50]: loss = 3.993372 * 64, metric = 92.19% * 64;
Finished Epoch[15 of 80]: [Training] loss = 3773668226434773158985728.000000 * 394, metric = 539020287967777306072076779520.00% * 394 21.680s ( 18.2 samples/s);
Finished Evaluation [15]: Minibatch[1-14]: metric = 98.81% * 84;
 Minibatch[   1-  10]: loss = 4.132475 * 66, metric = 93.94% * 66;
 Minibatch[  11-  20]: loss = 3.971749 * 58, metric = 91.38% * 58;
 Minibatch[  21-  30]: loss = 3.897157 * 72, metric = 87.50% * 72;
 Minibatch[  31-  40]: loss = 3.822885 * 69, metric = 92.75% * 69;
 Minibatch[  41-  50]: loss = 3.802678 * 76, metric = 93.42% * 76;
Finished Epoch[16 of 80]: [Training] loss = -2594424306978175777192804352.000000 * 399, metric = 13601598339436452578816356777984.00% * 399 23.640s ( 16.9 samples/s);
Finished Evaluation [16]: Minibatch[1-14]: metric = 98.81% * 84;
 Minibatch[   1-  10]: loss = 4.231116 * 67, metric = 97.01% * 67;
 Minibatch[  11-  20]: loss = 3.865887 * 75, metric = 96.00% * 75;
 Minibatch[  21-  30]: loss = 3.868793 * 73, metric = 94.52% * 73;
 Minibatch[  31-  40]: loss = 3.891150 * 64, metric = 95.31% * 64;
 Minibatch[  41-  50]: loss = 3.930257 * 69, metric = 95.65% * 69;
Finished Epoch[17 of 80]: [Training] loss = 3.945358 * 399, metric = 14789722151263747765772513968128.00% * 399 19.961s ( 20.0 samples/s);
Finished Evaluation [17]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.797048 * 67, metric = 88.06% * 67;
 Minibatch[  11-  20]: loss = 3.897835 * 69, metric = 95.65% * 69;
 Minibatch[  21-  30]: loss = 3.881977 * 70, metric = 91.43% * 70;
 Minibatch[  31-  40]: loss = 3.899444 * 66, metric = 90.91% * 66;
 Minibatch[  41-  50]: loss = 3.692620 * 71, metric = 90.14% * 71;
Finished Epoch[18 of 80]: [Training] loss = 3.841541 * 401, metric = 2968751296805871623601521688576.00% * 401 21.821s ( 18.4 samples/s);
Finished Evaluation [18]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.855891 * 70, metric = 95.71% * 70;
 Minibatch[  11-  20]: loss = 3.856574 * 70, metric = 94.29% * 70;
 Minibatch[  21-  30]: loss = 3.982866 * 65, metric = 92.31% * 65;
 Minibatch[  31-  40]: loss = 3.591829 * 70, metric = 91.43% * 70;
 Minibatch[  41-  50]: loss = 3.881942 * 70, metric = 91.43% * 70;
Finished Epoch[19 of 80]: [Training] loss = 3.852883 * 398, metric = 746537588317089246377840476160.00% * 398 25.895s ( 15.4 samples/s);
Finished Evaluation [19]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.929646 * 73, metric = 94.52% * 73;
 Minibatch[  11-  20]: loss = 3.763578 * 78, metric = 94.87% * 78;
 Minibatch[  21-  30]: loss = 3.898835 * 71, metric = 92.96% * 71;
 Minibatch[  31-  40]: loss = 3.821717 * 58, metric = 94.83% * 58;
 Minibatch[  41-  50]: loss = 3.901772 * 69, metric = 98.55% * 69;
Finished Epoch[20 of 80]: [Training] loss = 3.835426 * 398, metric = 1475408001531375736042473652224.00% * 398 25.330s ( 15.7 samples/s);
Finished Evaluation [20]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.730201 * 58, metric = 89.66% * 58;
 Minibatch[  11-  20]: loss = 3.683156 * 65, metric = 86.15% * 65;
 Minibatch[  21-  30]: loss = 3.849152 * 73, metric = 94.52% * 73;
 Minibatch[  31-  40]: loss = 3.748833 * 67, metric = 94.03% * 67;
 Minibatch[  41-  50]: loss = 3.722985 * 66, metric = 89.39% * 66;
Finished Epoch[21 of 80]: [Training] loss = 3.778708 * 405, metric = 726291663028472976977816453120.00% * 405 24.320s ( 16.7 samples/s);
Finished Evaluation [21]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.611203 * 70, metric = 90.00% * 70;
 Minibatch[  11-  20]: loss = 3.878151 * 78, metric = 91.03% * 78;
 Minibatch[  21-  30]: loss = 3.873454 * 61, metric = 96.72% * 61;
 Minibatch[  31-  40]: loss = 3.691286 * 76, metric = 92.11% * 76;
 Minibatch[  41-  50]: loss = 3.933507 * 65, metric = 95.38% * 65;
Finished Epoch[22 of 80]: [Training] loss = 3.773425 * 397, metric = 91.69% * 397 32.282s ( 12.3 samples/s);
Finished Evaluation [22]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.869734 * 72, metric = 93.06% * 72;
 Minibatch[  11-  20]: loss = 3.793501 * 57, metric = 91.23% * 57;
 Minibatch[  21-  30]: loss = 3.820014 * 69, metric = 94.20% * 69;
 Minibatch[  31-  40]: loss = 3.887664 * 76, metric = 85.53% * 76;
 Minibatch[  41-  50]: loss = 3.730214 * 66, metric = 92.42% * 66;
Finished Epoch[23 of 80]: [Training] loss = 3.817711 * 395, metric = 1473695264854370167146663641088.00% * 395 21.648s ( 18.2 samples/s);
Finished Evaluation [23]: Minibatch[1-14]: metric = 96.43% * 84;
 Minibatch[   1-  10]: loss = 3.687471 * 69, metric = 94.20% * 69;
 Minibatch[  11-  20]: loss = 3.820314 * 71, metric = 90.14% * 71;
 Minibatch[  21-  30]: loss = 3.692774 * 59, metric = 91.53% * 59;
 Minibatch[  31-  40]: loss = 3.817989 * 76, metric = 90.79% * 76;
 Minibatch[  41-  50]: loss = 3.733175 * 64, metric = 98.44% * 64;
Finished Epoch[24 of 80]: [Training] loss = 3.776312 * 400, metric = 10468875682751643147373511704576.00% * 400 22.232s ( 18.0 samples/s);
Finished Evaluation [24]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.875349 * 73, metric = 87.67% * 73;
 Minibatch[  11-  20]: loss = 3.552810 * 69, metric = 88.41% * 69;
 Minibatch[  21-  30]: loss = 3.599571 * 77, metric = 83.12% * 77;
 Minibatch[  31-  40]: loss = 3.864522 * 74, metric = 91.89% * 74;
 Minibatch[  41-  50]: loss = 3.830920 * 68, metric = 91.18% * 68;
Finished Epoch[25 of 80]: [Training] loss = 3.762328 * 399, metric = 1439163469543281136075819450368.00% * 399 24.025s ( 16.6 samples/s);
Finished Evaluation [25]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.764005 * 63, metric = 90.48% * 63;
 Minibatch[  11-  20]: loss = 3.725927 * 66, metric = 90.91% * 66;
 Minibatch[  21-  30]: loss = 3.625295 * 64, metric = 90.62% * 64;
 Minibatch[  31-  40]: loss = 3.729086 * 76, metric = 97.37% * 76;
 Minibatch[  41-  50]: loss = 3.758198 * 73, metric = 89.04% * 73;
Finished Epoch[26 of 80]: [Training] loss = 3.712863 * 402, metric = 91.79% * 402 22.951s ( 17.5 samples/s);
Finished Evaluation [26]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.517704 * 69, metric = 91.30% * 69;
 Minibatch[  11-  20]: loss = 3.820177 * 66, metric = 93.94% * 66;
 Minibatch[  21-  30]: loss = 3.648028 * 66, metric = 84.85% * 66;
 Minibatch[  31-  40]: loss = 3.761388 * 72, metric = 90.28% * 72;
 Minibatch[  41-  50]: loss = 3.752516 * 76, metric = 90.79% * 76;
Finished Epoch[27 of 80]: [Training] loss = 3.728919 * 398, metric = 90.70% * 398 21.503s ( 18.5 samples/s);
Finished Evaluation [27]: Minibatch[1-14]: metric = 96.43% * 84;
 Minibatch[   1-  10]: loss = 3.673516 * 67, metric = 91.04% * 67;
 Minibatch[  11-  20]: loss = 3.697270 * 71, metric = 91.55% * 71;
 Minibatch[  21-  30]: loss = 3.514959 * 67, metric = 83.58% * 67;
 Minibatch[  31-  40]: loss = 3.905227 * 58, metric = 93.10% * 58;
 Minibatch[  41-  50]: loss = 3.826958 * 70, metric = 95.71% * 70;
Finished Epoch[28 of 80]: [Training] loss = 3.741947 * 396, metric = 877574898278525860520774336512.00% * 396 20.470s ( 19.3 samples/s);
Finished Evaluation [28]: Minibatch[1-14]: metric = 96.43% * 84;
 Minibatch[   1-  10]: loss = 3.776176 * 69, metric = 94.20% * 69;
 Minibatch[  11-  20]: loss = 3.655544 * 67, metric = 89.55% * 67;
 Minibatch[  21-  30]: loss = 3.669721 * 67, metric = 89.55% * 67;
 Minibatch[  31-  40]: loss = 3.972745 * 67, metric = 97.01% * 67;
 Minibatch[  41-  50]: loss = 3.618656 * 69, metric = 94.20% * 69;
Finished Epoch[29 of 80]: [Training] loss = 3.735749 * 404, metric = 9244265534853271912935680114688.00% * 404 20.421s ( 19.8 samples/s);
Finished Evaluation [29]: Minibatch[1-14]: metric = 96.43% * 84;
 Minibatch[   1-  10]: loss = 3.514786 * 69, metric = 81.16% * 69;
 Minibatch[  11-  20]: loss = 3.725928 * 68, metric = 91.18% * 68;
 Minibatch[  21-  30]: loss = 3.629574 * 63, metric = 92.06% * 63;
 Minibatch[  31-  40]: loss = 3.930977 * 68, metric = 97.06% * 68;
 Minibatch[  41-  50]: loss = 3.527713 * 66, metric = 87.88% * 66;
Finished Epoch[30 of 80]: [Training] loss = 88367944374519008.000000 * 395, metric = 12625601349618601712140767199232.00% * 395 20.535s ( 19.2 samples/s);
Finished Evaluation [30]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.456850 * 65, metric = 86.15% * 65;
 Minibatch[  11-  20]: loss = 3.837166 * 72, metric = 90.28% * 72;
 Minibatch[  21-  30]: loss = 3.602220 * 64, metric = 92.19% * 64;
 Minibatch[  31-  40]: loss = 3.890269 * 69, metric = 97.10% * 69;
 Minibatch[  41-  50]: loss = 3.787978 * 75, metric = 90.67% * 75;
Finished Epoch[31 of 80]: [Training] loss = 3.727976 * 401, metric = 8683101559482539626134482452480.00% * 401 28.065s ( 14.3 samples/s);
Finished Evaluation [31]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.868080 * 82, metric = 90.24% * 82;
 Minibatch[  11-  20]: loss = 3.627276 * 69, metric = 84.06% * 69;
 Minibatch[  21-  30]: loss = 3.858917 * 63, metric = 95.24% * 63;
 Minibatch[  31-  40]: loss = 3.546020 * 65, metric = 87.69% * 65;
 Minibatch[  41-  50]: loss = 3.753254 * 61, metric = 88.52% * 61;
Finished Epoch[32 of 80]: [Training] loss = 3.716957 * 397, metric = 1329336201567185267334508969984.00% * 397 26.779s ( 14.8 samples/s);
Finished Evaluation [32]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.617347 * 73, metric = 86.30% * 73;
 Minibatch[  11-  20]: loss = 3.727141 * 71, metric = 91.55% * 71;
 Minibatch[  21-  30]: loss = 3.662421 * 58, metric = 94.83% * 58;
 Minibatch[  31-  40]: loss = 3.594523 * 67, metric = 91.04% * 67;
 Minibatch[  41-  50]: loss = 3.741521 * 69, metric = 92.75% * 69;
Finished Epoch[33 of 80]: [Training] loss = 3.667019 * 402, metric = 9251982675097817795549942775808.00% * 402 17.040s ( 23.6 samples/s);
Finished Evaluation [33]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.767691 * 66, metric = 90.91% * 66;
 Minibatch[  11-  20]: loss = 3.694995 * 66, metric = 87.88% * 66;
 Minibatch[  21-  30]: loss = 3.604895 * 73, metric = 86.30% * 73;
 Minibatch[  31-  40]: loss = 3.806543 * 64, metric = 95.31% * 64;
 Minibatch[  41-  50]: loss = 3.778683 * 69, metric = 89.86% * 69;
Finished Epoch[34 of 80]: [Training] loss = 3.700150 * 394, metric = 90.61% * 394 17.185s ( 22.9 samples/s);
Finished Evaluation [34]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.754485 * 71, metric = 91.55% * 71;
 Minibatch[  11-  20]: loss = 3.544285 * 71, metric = 91.55% * 71;
 Minibatch[  21-  30]: loss = 3.555817 * 65, metric = 90.77% * 65;
 Minibatch[  31-  40]: loss = 3.620830 * 70, metric = 82.86% * 70;
 Minibatch[  41-  50]: loss = 3.696469 * 67, metric = 95.52% * 67;
Finished Epoch[35 of 80]: [Training] loss = 3.661020 * 406, metric = 437277960213355275759004942336.00% * 406 19.884s ( 20.4 samples/s);
Finished Evaluation [35]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.651890 * 66, metric = 93.94% * 66;
 Minibatch[  11-  20]: loss = 3.539267 * 70, metric = 91.43% * 70;
 Minibatch[  21-  30]: loss = 3.657650 * 71, metric = 90.14% * 71;
 Minibatch[  31-  40]: loss = 3.793781 * 68, metric = 88.24% * 68;
 Minibatch[  41-  50]: loss = 3.705865 * 65, metric = 89.23% * 65;
Finished Epoch[36 of 80]: [Training] loss = 3.669638 * 392, metric = 90.31% * 392 19.585s ( 20.0 samples/s);
Finished Evaluation [36]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.572668 * 67, metric = 83.58% * 67;
 Minibatch[  11-  20]: loss = 3.582087 * 71, metric = 90.14% * 71;
 Minibatch[  21-  30]: loss = 3.632587 * 62, metric = 90.32% * 62;
 Minibatch[  31-  40]: loss = 3.662694 * 71, metric = 91.55% * 71;
 Minibatch[  41-  50]: loss = 3.780776 * 66, metric = 90.91% * 66;
Finished Epoch[37 of 80]: [Training] loss = 3.696550 * 403, metric = 90.57% * 403 19.526s ( 20.6 samples/s);
Finished Evaluation [37]: Minibatch[1-14]: metric = 95.24% * 84;
 Minibatch[   1-  10]: loss = 3.853116 * 67, metric = 92.54% * 67;
 Minibatch[  11-  20]: loss = 3.543891 * 76, metric = 92.11% * 76;
 Minibatch[  21-  30]: loss = 3.687485 * 73, metric = 93.15% * 73;
 Minibatch[  31-  40]: loss = 3.593333 * 65, metric = 90.77% * 65;
 Minibatch[  41-  50]: loss = 3.708992 * 62, metric = 90.32% * 62;
Finished Epoch[38 of 80]: [Training] loss = 3.685575 * 397, metric = 7309677091127315071874218590208.00% * 397 26.262s ( 15.1 samples/s);
Finished Evaluation [38]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.800143 * 65, metric = 93.85% * 65;
 Minibatch[  11-  20]: loss = 3.791955 * 70, metric = 95.71% * 70;
 Minibatch[  21-  30]: loss = 3.542618 * 67, metric = 82.09% * 67;
 Minibatch[  31-  40]: loss = 3.630161 * 68, metric = 88.24% * 68;
 Minibatch[  41-  50]: loss = 3.647172 * 74, metric = 87.84% * 74;
Finished Epoch[39 of 80]: [Training] loss = 3.689921 * 398, metric = 3145725220205223089674580393984.00% * 398 20.483s ( 19.4 samples/s);
Finished Evaluation [39]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.800537 * 80, metric = 91.25% * 80;
 Minibatch[  11-  20]: loss = 3.774749 * 61, metric = 85.25% * 61;
 Minibatch[  21-  30]: loss = 3.560575 * 72, metric = 88.89% * 72;
 Minibatch[  31-  40]: loss = 3.645840 * 68, metric = 95.59% * 68;
 Minibatch[  41-  50]: loss = 3.624173 * 70, metric = 92.86% * 70;
Finished Epoch[40 of 80]: [Training] loss = 3.665420 * 398, metric = 90.20% * 398 18.129s ( 22.0 samples/s);
Finished Evaluation [40]: Minibatch[1-14]: metric = 96.43% * 84;
Learning rate per 60 samples: 0.01
 Minibatch[   1-  10]: loss = 3.646686 * 68, metric = 94.12% * 68;
 Minibatch[  11-  20]: loss = 3.787197 * 66, metric = 90.91% * 66;
 Minibatch[  21-  30]: loss = 3.725665 * 63, metric = 90.48% * 63;
 Minibatch[  31-  40]: loss = 3.521303 * 73, metric = 84.93% * 73;
 Minibatch[  41-  50]: loss = 3.517488 * 69, metric = 91.30% * 69;
Finished Epoch[41 of 80]: [Training] loss = 3.640745 * 403, metric = 91.07% * 403 19.244s ( 20.9 samples/s);
Finished Evaluation [41]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.756173 * 78, metric = 91.03% * 78;
 Minibatch[  11-  20]: loss = 3.521531 * 70, metric = 87.14% * 70;
 Minibatch[  21-  30]: loss = 3.813149 * 71, metric = 94.37% * 71;
 Minibatch[  31-  40]: loss = 3.523644 * 70, metric = 80.00% * 70;
 Minibatch[  41-  50]: loss = 3.789169 * 54, metric = 90.74% * 54;
Finished Epoch[42 of 80]: [Training] loss = 3.661358 * 400, metric = 554032342568499223955993788416.00% * 400 21.190s ( 18.9 samples/s);
Finished Evaluation [42]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.649185 * 70, metric = 88.57% * 70;
 Minibatch[  11-  20]: loss = 3.834921 * 72, metric = 87.50% * 72;
 Minibatch[  21-  30]: loss = 3.481413 * 66, metric = 92.42% * 66;
 Minibatch[  31-  40]: loss = 3.592360 * 77, metric = 89.61% * 77;
 Minibatch[  41-  50]: loss = 3.913841 * 60, metric = 91.67% * 60;
Finished Epoch[43 of 80]: [Training] loss = 3.666315 * 398, metric = 88.94% * 398 20.344s ( 19.6 samples/s);
Finished Evaluation [43]: Minibatch[1-14]: metric = 96.43% * 84;
 Minibatch[   1-  10]: loss = 3.606226 * 69, metric = 89.86% * 69;
 Minibatch[  11-  20]: loss = 3.589948 * 75, metric = 88.00% * 75;
 Minibatch[  21-  30]: loss = 3.666611 * 74, metric = 86.49% * 74;
 Minibatch[  31-  40]: loss = 3.771981 * 65, metric = 87.69% * 65;
 Minibatch[  41-  50]: loss = 3.911005 * 61, metric = 96.72% * 61;
Finished Epoch[44 of 80]: [Training] loss = 3.678611 * 400, metric = 89.25% * 400 18.079s ( 22.1 samples/s);
Finished Evaluation [44]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.730214 * 64, metric = 96.88% * 64;
 Minibatch[  11-  20]: loss = 3.549665 * 75, metric = 85.33% * 75;
 Minibatch[  21-  30]: loss = 3.576680 * 73, metric = 91.78% * 73;
 Minibatch[  31-  40]: loss = 3.749056 * 68, metric = 94.12% * 68;
 Minibatch[  41-  50]: loss = 3.490787 * 69, metric = 84.06% * 69;
Finished Epoch[45 of 80]: [Training] loss = 3.628207 * 395, metric = 9233278373373233057121009926144.00% * 395 19.891s ( 19.9 samples/s);
Finished Evaluation [45]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.528566 * 71, metric = 90.14% * 71;
 Minibatch[  11-  20]: loss = 3.485757 * 67, metric = 83.58% * 67;
 Minibatch[  21-  30]: loss = 3.801804 * 74, metric = 97.30% * 74;
 Minibatch[  31-  40]: loss = 3.657537 * 60, metric = 90.00% * 60;
 Minibatch[  41-  50]: loss = 3.644586 * 67, metric = 88.06% * 67;
Finished Epoch[46 of 80]: [Training] loss = 3.620793 * 401, metric = 8789933821649692144652196511744.00% * 401 17.278s ( 23.2 samples/s);
Finished Evaluation [46]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.623046 * 72, metric = 90.28% * 72;
 Minibatch[  11-  20]: loss = 3.855816 * 64, metric = 95.31% * 64;
 Minibatch[  21-  30]: loss = 3.559540 * 65, metric = 83.08% * 65;
 Minibatch[  31-  40]: loss = 3.476651 * 70, metric = 84.29% * 70;
 Minibatch[  41-  50]: loss = 3.725476 * 74, metric = 91.89% * 74;
Finished Epoch[47 of 80]: [Training] loss = 3.632296 * 398, metric = 13964263262342221961836489605120.00% * 398 24.725s ( 16.1 samples/s);
Finished Evaluation [47]: Minibatch[1-14]: metric = 96.43% * 84;
 Minibatch[   1-  10]: loss = 3.685093 * 61, metric = 95.08% * 61;
 Minibatch[  11-  20]: loss = 3.536742 * 65, metric = 84.62% * 65;
 Minibatch[  21-  30]: loss = 3.708634 * 71, metric = 91.55% * 71;
 Minibatch[  31-  40]: loss = 3.465177 * 77, metric = 89.61% * 77;
 Minibatch[  41-  50]: loss = 3.730248 * 73, metric = 90.41% * 73;
Finished Epoch[48 of 80]: [Training] loss = 3.639604 * 405, metric = 89.38% * 405 21.962s ( 18.4 samples/s);
Finished Evaluation [48]: Minibatch[1-14]: metric = 96.43% * 84;
 Minibatch[   1-  10]: loss = 3.891150 * 68, metric = 95.59% * 68;
 Minibatch[  11-  20]: loss = 3.588251 * 68, metric = 88.24% * 68;
 Minibatch[  21-  30]: loss = 3.594574 * 65, metric = 90.77% * 65;
 Minibatch[  31-  40]: loss = 3.916921 * 63, metric = 95.24% * 63;
 Minibatch[  41-  50]: loss = 3.511520 * 76, metric = 90.79% * 76;
Finished Epoch[49 of 80]: [Training] loss = 41340918185323304.000000 * 393, metric = 9495929589933765424640132382720.00% * 393 21.370s ( 18.4 samples/s);
Finished Evaluation [49]: Minibatch[1-14]: metric = 96.43% * 84;
 Minibatch[   1-  10]: loss = 3.687708 * 63, metric = 88.89% * 63;
 Minibatch[  11-  20]: loss = 3.588941 * 69, metric = 89.86% * 69;
 Minibatch[  21-  30]: loss = 3.663749 * 72, metric = 94.44% * 72;
 Minibatch[  31-  40]: loss = 3.582486 * 67, metric = 83.58% * 67;
 Minibatch[  41-  50]: loss = 3.731946 * 68, metric = 89.71% * 68;
Finished Epoch[50 of 80]: [Training] loss = 3.663338 * 397, metric = 89.67% * 397 21.195s ( 18.7 samples/s);
Finished Evaluation [50]: Minibatch[1-14]: metric = 96.43% * 84;
 Minibatch[   1-  10]: loss = 3.446163 * 68, metric = 83.82% * 68;
 Minibatch[  11-  20]: loss = 3.427419 * 67, metric = 88.06% * 67;
 Minibatch[  21-  30]: loss = 3.734463 * 67, metric = 92.54% * 67;
 Minibatch[  31-  40]: loss = 3.540238 * 81, metric = 86.42% * 81;
 Minibatch[  41-  50]: loss = 3.819866 * 58, metric = 93.10% * 58;
 Minibatch[  51-  60]: loss = 3.859629 * 63, metric = 93.65% * 63;
Finished Epoch[51 of 80]: [Training] loss = 3.627855 * 404, metric = 89.36% * 404 23.351s ( 17.3 samples/s);
Finished Evaluation [51]: Minibatch[1-14]: metric = 96.43% * 84;
 Minibatch[   1-  10]: loss = 3.720666 * 70, metric = 92.86% * 70;
 Minibatch[  11-  20]: loss = 3.604609 * 62, metric = 85.48% * 62;
 Minibatch[  21-  30]: loss = 3.543537 * 67, metric = 89.55% * 67;
 Minibatch[  31-  40]: loss = 3.676034 * 73, metric = 91.78% * 73;
 Minibatch[  41-  50]: loss = 3.592638 * 75, metric = 89.33% * 75;
Finished Epoch[52 of 80]: [Training] loss = 3.605995 * 397, metric = 670291813580869232178256412672.00% * 397 26.783s ( 14.8 samples/s);
Finished Evaluation [52]: Minibatch[1-14]: metric = 96.43% * 84;
 Minibatch[   1-  10]: loss = 3.661080 * 70, metric = 91.43% * 70;
 Minibatch[  11-  20]: loss = 3.505918 * 71, metric = 85.92% * 71;
 Minibatch[  21-  30]: loss = 3.950570 * 59, metric = 93.22% * 59;
 Minibatch[  31-  40]: loss = 3.686207 * 73, metric = 97.26% * 73;
 Minibatch[  41-  50]: loss = 3.518438 * 71, metric = 87.32% * 71;
Finished Epoch[53 of 80]: [Training] loss = 3.678160 * 399, metric = 6161925201468487478152651603968.00% * 399 26.459s ( 15.1 samples/s);
Finished Evaluation [53]: Minibatch[1-14]: metric = 96.43% * 84;
 Minibatch[   1-  10]: loss = 3.583952 * 65, metric = 89.23% * 65;
 Minibatch[  11-  20]: loss = 3.439196 * 66, metric = 89.39% * 66;
 Minibatch[  21-  30]: loss = 3.500796 * 70, metric = 87.14% * 70;
 Minibatch[  31-  40]: loss = 3.855718 * 66, metric = 92.42% * 66;
 Minibatch[  41-  50]: loss = 3.492035 * 70, metric = 91.43% * 70;
Finished Epoch[54 of 80]: [Training] loss = 3.597285 * 401, metric = 716249205273922258794534928384.00% * 401 30.067s ( 13.3 samples/s);
Finished Evaluation [54]: Minibatch[1-14]: metric = 95.24% * 84;
 Minibatch[   1-  10]: loss = 3.714876 * 72, metric = 93.06% * 72;
 Minibatch[  11-  20]: loss = 3.588316 * 65, metric = 92.31% * 65;
 Minibatch[  21-  30]: loss = 3.580430 * 67, metric = 80.60% * 67;
 Minibatch[  31-  40]: loss = 3.564378 * 71, metric = 90.14% * 71;
 Minibatch[  41-  50]: loss = 3.484520 * 66, metric = 86.36% * 66;
Finished Epoch[55 of 80]: [Training] loss = 3.612087 * 402, metric = 1526279072009207431660805554176.00% * 402 31.836s ( 12.6 samples/s);
Finished Evaluation [55]: Minibatch[1-14]: metric = 95.24% * 84;
 Minibatch[   1-  10]: loss = 3.656192 * 64, metric = 87.50% * 64;
 Minibatch[  11-  20]: loss = 3.493255 * 74, metric = 82.43% * 74;
 Minibatch[  21-  30]: loss = 3.626363 * 67, metric = 88.06% * 67;
 Minibatch[  31-  40]: loss = 3.639136 * 69, metric = 88.41% * 69;
 Minibatch[  41-  50]: loss = 3.680326 * 67, metric = 94.03% * 67;
Finished Epoch[56 of 80]: [Training] loss = 3.602837 * 392, metric = 55461268093181686269333745958912.00% * 392 23.947s ( 16.4 samples/s);
Finished Evaluation [56]: Minibatch[1-14]: metric = 95.24% * 84;
 Minibatch[   1-  10]: loss = 3.512936 * 64, metric = 90.62% * 64;
 Minibatch[  11-  20]: loss = 3.663138 * 71, metric = 92.96% * 71;
 Minibatch[  21-  30]: loss = 3.597913 * 68, metric = 92.65% * 68;
 Minibatch[  31-  40]: loss = 3.453062 * 76, metric = 84.21% * 76;
 Minibatch[  41-  50]: loss = 3.848295 * 68, metric = 89.71% * 68;
Finished Epoch[57 of 80]: [Training] loss = 3.611985 * 403, metric = 782591379741688649870162788352.00% * 403 23.747s ( 17.0 samples/s);
Finished Evaluation [57]: Minibatch[1-14]: metric = 95.24% * 84;
 Minibatch[   1-  10]: loss = 3.707912 * 71, metric = 90.14% * 71;
 Minibatch[  11-  20]: loss = 3.649586 * 66, metric = 86.36% * 66;
 Minibatch[  21-  30]: loss = 3.554434 * 67, metric = 86.57% * 67;
 Minibatch[  31-  40]: loss = 3.592458 * 67, metric = 88.06% * 67;
 Minibatch[  41-  50]: loss = 3.784404 * 68, metric = 91.18% * 68;
Finished Epoch[58 of 80]: [Training] loss = nan * 395, metric = 5731447529758306328077670547456.00% * 395 21.011s ( 18.8 samples/s);
Finished Evaluation [58]: Minibatch[1-14]: metric = 95.24% * 84;
 Minibatch[   1-  10]: loss = 3.656361 * 68, metric = 88.24% * 68;
 Minibatch[  11-  20]: loss = 3.647476 * 69, metric = 86.96% * 69;
 Minibatch[  21-  30]: loss = 3.662371 * 70, metric = 91.43% * 70;
 Minibatch[  31-  40]: loss = 3.849343 * 58, metric = 82.76% * 58;
 Minibatch[  41-  50]: loss = 3.465455 * 69, metric = 88.41% * 69;
Finished Epoch[59 of 80]: [Training] loss = 3.636188 * 400, metric = 646254266465572703293505798144.00% * 400 31.823s ( 12.6 samples/s);
Finished Evaluation [59]: Minibatch[1-14]: metric = 95.24% * 84;
 Minibatch[   1-  10]: loss = 3.529733 * 65, metric = 89.23% * 65;
 Minibatch[  11-  20]: loss = 3.742965 * 71, metric = 92.96% * 71;
 Minibatch[  21-  30]: loss = 3.741802 * 71, metric = 90.14% * 71;
 Minibatch[  31-  40]: loss = 3.461352 * 67, metric = 86.57% * 67;
 Minibatch[  41-  50]: loss = 3.589633 * 76, metric = 90.79% * 76;
Finished Epoch[60 of 80]: [Training] loss = 3.617433 * 399, metric = 28156734343688064577620139835392.00% * 399 30.168s ( 13.2 samples/s);
Finished Evaluation [60]: Minibatch[1-14]: metric = 95.24% * 84;
 Minibatch[   1-  10]: loss = 3.493378 * 67, metric = 82.09% * 67;
 Minibatch[  11-  20]: loss = 3.595771 * 80, metric = 88.75% * 80;
 Minibatch[  21-  30]: loss = 3.696550 * 74, metric = 93.24% * 74;
 Minibatch[  31-  40]: loss = 3.670306 * 63, metric = 88.89% * 63;
 Minibatch[  41-  50]: loss = 3.734294 * 69, metric = 95.65% * 69;
Finished Epoch[61 of 80]: [Training] loss = 3.662676 * 403, metric = 9807555002769890848934415302656.00% * 403 33.659s ( 12.0 samples/s);
Finished Evaluation [61]: Minibatch[1-14]: metric = 96.43% * 84;
 Minibatch[   1-  10]: loss = 3.499724 * 68, metric = 82.35% * 68;
 Minibatch[  11-  20]: loss = 3.613573 * 65, metric = 90.77% * 65;
 Minibatch[  21-  30]: loss = 3.566969 * 66, metric = 96.97% * 66;
 Minibatch[  31-  40]: loss = 3.773180 * 71, metric = 92.96% * 71;
 Minibatch[  41-  50]: loss = 3.557000 * 71, metric = 85.92% * 71;
Finished Epoch[62 of 80]: [Training] loss = 3.620951 * 393, metric = 90.08% * 393 28.089s ( 14.0 samples/s);
Finished Evaluation [62]: Minibatch[1-14]: metric = 95.24% * 84;
 Minibatch[   1-  10]: loss = 3.726644 * 68, metric = 91.18% * 68;
 Minibatch[  11-  20]: loss = 3.620008 * 72, metric = 88.89% * 72;
 Minibatch[  21-  30]: loss = 3.630437 * 73, metric = 84.93% * 73;
 Minibatch[  31-  40]: loss = 3.576979 * 69, metric = 95.65% * 69;
 Minibatch[  41-  50]: loss = 3.906622 * 61, metric = 90.16% * 61;
Finished Epoch[63 of 80]: [Training] loss = 3.667939 * 401, metric = 1094280459806296969746787074048.00% * 401 22.533s ( 17.8 samples/s);
Finished Evaluation [63]: Minibatch[1-14]: metric = 95.24% * 84;
 Minibatch[   1-  10]: loss = 3.584584 * 74, metric = 90.54% * 74;
 Minibatch[  11-  20]: loss = 3.416768 * 76, metric = 85.53% * 76;
 Minibatch[  21-  30]: loss = 3.744524 * 62, metric = 88.71% * 62;
 Minibatch[  31-  40]: loss = 3.677603 * 72, metric = 91.67% * 72;
 Minibatch[  41-  50]: loss = 3.731030 * 70, metric = 87.14% * 70;
Finished Epoch[64 of 80]: [Training] loss = 3.630320 * 397, metric = 89.67% * 397 22.361s ( 17.8 samples/s);
Finished Evaluation [64]: Minibatch[1-14]: metric = 95.24% * 84;
 Minibatch[   1-  10]: loss = 3.492247 * 71, metric = 87.32% * 71;
 Minibatch[  11-  20]: loss = 3.771877 * 75, metric = 92.00% * 75;
 Minibatch[  21-  30]: loss = 3.705938 * 63, metric = 92.06% * 63;
 Minibatch[  31-  40]: loss = 3.469575 * 69, metric = 85.51% * 69;
 Minibatch[  41-  50]: loss = 3.684539 * 64, metric = 93.75% * 64;
Finished Epoch[65 of 80]: [Training] loss = 3.632361 * 399, metric = 90.48% * 399 24.531s ( 16.3 samples/s);
Finished Evaluation [65]: Minibatch[1-14]: metric = 95.24% * 84;
 Minibatch[   1-  10]: loss = 3.765205 * 65, metric = 92.31% * 65;
 Minibatch[  11-  20]: loss = 3.575572 * 62, metric = 85.48% * 62;
 Minibatch[  21-  30]: loss = 3.597286 * 72, metric = 83.33% * 72;
 Minibatch[  31-  40]: loss = 3.481095 * 72, metric = 91.67% * 72;
 Minibatch[  41-  50]: loss = 3.636250 * 64, metric = 93.75% * 64;
Finished Epoch[66 of 80]: [Training] loss = 3.597836 * 402, metric = 208896705391884241000315486208.00% * 402 19.410s ( 20.7 samples/s);
Finished Evaluation [66]: Minibatch[1-14]: metric = 96.43% * 84;
 Minibatch[   1-  10]: loss = 3.723678 * 72, metric = 95.83% * 72;
 Minibatch[  11-  20]: loss = 3.617026 * 72, metric = 87.50% * 72;
 Minibatch[  21-  30]: loss = 3.488851 * 66, metric = 86.36% * 66;
 Minibatch[  31-  40]: loss = 3.698662 * 75, metric = 90.67% * 75;
 Minibatch[  41-  50]: loss = 3.738636 * 65, metric = 90.77% * 65;
Finished Epoch[67 of 80]: [Training] loss = 3.626910 * 399, metric = 783433848536039547445413150720.00% * 399 20.003s ( 19.9 samples/s);
Finished Evaluation [67]: Minibatch[1-14]: metric = 95.24% * 84;
 Minibatch[   1-  10]: loss = 3.682313 * 64, metric = 90.62% * 64;
 Minibatch[  11-  20]: loss = 3.697071 * 72, metric = 86.11% * 72;
 Minibatch[  21-  30]: loss = 3.728272 * 70, metric = 90.00% * 70;
 Minibatch[  31-  40]: loss = 3.643257 * 63, metric = 93.65% * 63;
 Minibatch[  41-  50]: loss = 3.680423 * 73, metric = 93.15% * 73;
Finished Epoch[68 of 80]: [Training] loss = 3.657391 * 397, metric = 786232291282879261664681656320.00% * 397 17.370s ( 22.9 samples/s);
Finished Evaluation [68]: Minibatch[1-14]: metric = 96.43% * 84;
 Minibatch[   1-  10]: loss = 3.620664 * 59, metric = 84.75% * 59;
 Minibatch[  11-  20]: loss = 3.604079 * 75, metric = 94.67% * 75;
 Minibatch[  21-  30]: loss = 3.618057 * 66, metric = 93.94% * 66;
 Minibatch[  31-  40]: loss = 3.617883 * 67, metric = 89.55% * 67;
 Minibatch[  41-  50]: loss = 3.562525 * 71, metric = 94.37% * 71;
Finished Epoch[69 of 80]: [Training] loss = 3.621573 * 398, metric = 91.46% * 398 21.901s ( 18.2 samples/s);
Finished Evaluation [69]: Minibatch[1-14]: metric = 95.24% * 84;
 Minibatch[   1-  10]: loss = 3.645263 * 74, metric = 89.19% * 74;
 Minibatch[  11-  20]: loss = 3.595766 * 69, metric = 81.16% * 69;
 Minibatch[  21-  30]: loss = 3.794031 * 60, metric = 86.67% * 60;
 Minibatch[  31-  40]: loss = 3.699097 * 78, metric = 89.74% * 78;
 Minibatch[  41-  50]: loss = 3.646391 * 68, metric = 86.76% * 68;
Finished Epoch[70 of 80]: [Training] loss = 3.655562 * 401, metric = 3400128588842505620207471427584.00% * 401 35.239s ( 11.4 samples/s);
Finished Evaluation [70]: Minibatch[1-14]: metric = 95.24% * 84;
 Minibatch[   1-  10]: loss = 3.771661 * 68, metric = 94.12% * 68;
 Minibatch[  11-  20]: loss = 3.598108 * 72, metric = 87.50% * 72;
 Minibatch[  21-  30]: loss = 3.607131 * 60, metric = 91.67% * 60;
 Minibatch[  31-  40]: loss = 3.613187 * 71, metric = 87.32% * 71;
 Minibatch[  41-  50]: loss = 3.921787 * 68, metric = 92.65% * 68;
Finished Epoch[71 of 80]: [Training] loss = nan * 400, metric = 1879533745600611130895490875392.00% * 400 24.568s ( 16.3 samples/s);
Finished Evaluation [71]: Minibatch[1-14]: metric = 95.24% * 84;
 Minibatch[   1-  10]: loss = 3.727784 * 68, metric = 92.65% * 68;
 Minibatch[  11-  20]: loss = 3.545901 * 70, metric = 88.57% * 70;
 Minibatch[  21-  30]: loss = 3.581785 * 64, metric = 90.62% * 64;
 Minibatch[  31-  40]: loss = 3.448285 * 71, metric = 88.73% * 71;
 Minibatch[  41-  50]: loss = 3.646360 * 63, metric = 92.06% * 63;
Finished Epoch[72 of 80]: [Training] loss = nan * 397, metric = 2679956501411943597101522354176.00% * 397 26.645s ( 14.9 samples/s);
Finished Evaluation [72]: Minibatch[1-14]: metric = 95.24% * 84;
 Minibatch[   1-  10]: loss = 3.519022 * 70, metric = 90.00% * 70;
 Minibatch[  11-  20]: loss = 3.567599 * 73, metric = 84.93% * 73;
 Minibatch[  21-  30]: loss = 3.364205 * 65, metric = 86.15% * 65;
 Minibatch[  31-  40]: loss = 3.588801 * 72, metric = 84.72% * 72;
 Minibatch[  41-  50]: loss = 3.695489 * 59, metric = 91.53% * 59;
Finished Epoch[73 of 80]: [Training] loss = nan * 403, metric = 60850334988358172524315200716800.00% * 403 27.919s ( 14.4 samples/s);
Finished Evaluation [73]: Minibatch[1-14]: metric = 96.43% * 84;
 Minibatch[   1-  10]: loss = 3.617230 * 76, metric = 89.47% * 76;
 Minibatch[  11-  20]: loss = 3.622326 * 57, metric = 92.98% * 57;
 Minibatch[  21-  30]: loss = 3.542960 * 67, metric = 91.04% * 67;
 Minibatch[  31-  40]: loss = 3.675076 * 76, metric = 78.95% * 76;
 Minibatch[  41-  50]: loss = 3.483761 * 59, metric = 91.53% * 59;
Finished Epoch[74 of 80]: [Training] loss = nan * 399, metric = 2777496768941085281339811299328.00% * 399 27.263s ( 14.6 samples/s);
Finished Evaluation [74]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.366140 * 61, metric = 86.89% * 61;
 Minibatch[  11-  20]: loss = 3.678946 * 68, metric = 91.18% * 68;
 Minibatch[  21-  30]: loss = 3.661970 * 69, metric = 89.86% * 69;
 Minibatch[  31-  40]: loss = 3.451355 * 71, metric = 92.96% * 71;
 Minibatch[  41-  50]: loss = 3.644652 * 69, metric = 88.41% * 69;
Finished Epoch[75 of 80]: [Training] loss = nan * 399, metric = 664862919229412952220115140608.00% * 399 26.380s ( 15.1 samples/s);
Finished Evaluation [75]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.703277 * 64, metric = 89.06% * 64;
 Minibatch[  11-  20]: loss = 3.726470 * 63, metric = 93.65% * 63;
 Minibatch[  21-  30]: loss = 3.579136 * 71, metric = 84.51% * 71;
 Minibatch[  31-  40]: loss = 3.632120 * 78, metric = 89.74% * 78;
 Minibatch[  41-  50]: loss = 3.572295 * 77, metric = 90.91% * 77;
Finished Epoch[76 of 80]: [Training] loss = nan * 397, metric = 556185355521197761440119783424.00% * 397 31.797s ( 12.5 samples/s);
Finished Evaluation [76]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.604604 * 66, metric = 89.39% * 66;
 Minibatch[  11-  20]: loss = 3.330233 * 72, metric = 88.89% * 72;
 Minibatch[  21-  30]: loss = 3.396017 * 71, metric = 88.73% * 71;
 Minibatch[  31-  40]: loss = 3.665322 * 60, metric = 90.00% * 60;
 Minibatch[  41-  50]: loss = 3.604385 * 65, metric = 90.77% * 65;
Finished Epoch[77 of 80]: [Training] loss = nan * 399, metric = 11064359367236166574018767355904.00% * 399 33.420s ( 11.9 samples/s);
Finished Evaluation [77]: Minibatch[1-14]: metric = 98.81% * 84;
 Minibatch[   1-  10]: loss = 3.471098 * 67, metric = 89.55% * 67;
 Minibatch[  11-  20]: loss = 3.636849 * 83, metric = 87.95% * 83;
 Minibatch[  21-  30]: loss = 3.536980 * 71, metric = 88.73% * 71;
 Minibatch[  31-  40]: loss = 3.617849 * 66, metric = 87.88% * 66;
 Minibatch[  41-  50]: loss = 3.499381 * 70, metric = 87.14% * 70;
Finished Epoch[78 of 80]: [Training] loss = nan * 400, metric = 1391940112627081975119598321664.00% * 400 35.354s ( 11.3 samples/s);
Finished Evaluation [78]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.513512 * 69, metric = 92.75% * 69;
 Minibatch[  11-  20]: loss = 3.775459 * 74, metric = 89.19% * 74;
 Minibatch[  21-  30]: loss = 3.537486 * 71, metric = 85.92% * 71;
 Minibatch[  31-  40]: loss = 3.850438 * 62, metric = 93.55% * 62;
 Minibatch[  41-  50]: loss = 3.541179 * 65, metric = 92.31% * 65;
Finished Epoch[79 of 80]: [Training] loss = 3.604448 * 397, metric = 89.92% * 397 31.900s ( 12.4 samples/s);
Finished Evaluation [79]: Minibatch[1-14]: metric = 97.62% * 84;
 Minibatch[   1-  10]: loss = 3.560928 * 62, metric = 82.26% * 62;
 Minibatch[  11-  20]: loss = 3.573524 * 75, metric = 84.00% * 75;
 Minibatch[  21-  30]: loss = 3.693662 * 71, metric = 90.14% * 71;
 Minibatch[  31-  40]: loss = 3.545795 * 67, metric = 92.54% * 67;
 Minibatch[  41-  50]: loss = 3.645178 * 69, metric = 88.41% * 69;
Finished Epoch[80 of 80]: [Training] loss = nan * 398, metric = 5084766297315604799335792902144.00% * 398 27.705s ( 14.4 samples/s);
Finished Evaluation [80]: Minibatch[1-14]: metric = 96.43% * 84;
 Minibatch[   1-  10]: loss = 3.618197 * 52, metric = 88.46% * 52;
 Minibatch[  11-  20]: loss = 4.166851 * 16, metric = 100.00% * 16;
 Minibatch[  21-  30]: loss = 4.090294 * 10, metric = 90.00% * 10;
Finished Evaluation [81]: Minibatch[1-14]: metric = 98.81% * 84;
